# -*- coding: utf-8 -*-
"""FCN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wIg27OpGjLGGAMXjI0NWqfQfNOl_aGlv
"""

from google.colab import drive
drive.mount('/content/drive')

"""# rectus femoris msucle

"""

# ==============================================================================
# STEP 0: SETUP AND IMPORTS
# ==============================================================================
import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import time
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive

# ==============================================================================
# STEP 1: MOUNT GOOGLE DRIVE
# ==============================================================================
print("--- Mounting Google Drive ---")
try:
    drive.mount('/content/drive', force_remount=True)
    print("✅ Google Drive mounted successfully.")
except Exception as e:
    print(f"❌ Error mounting drive: {e}")

# ==============================================================================
# STEP 2: DEFINE YOUR DATASET FILE PATHS
# ==============================================================================
# ==============================================================================
# STEP 2: DEFINE YOUR DATASET FILE PATHS
# ==============================================================================
print("\n--- Defining dataset file paths ---")
base_path = '/content/drive/MyDrive/intern RF transverse latest file/'

# Training and Validation sets (used for training and model selection)
X_train_path = os.path.join(base_path, 'X_train.npy')
y_train_path = os.path.join(base_path, 'y_train.npy')
X_val_path = os.path.join(base_path, 'X_val.npy')
y_val_path = os.path.join(base_path, 'y_val.npy')

# Test set (used for final external validation)
X_test_path = os.path.join(base_path, 'X_test.npy')
y_test_path = os.path.join(base_path, 'y_test.npy')

print("✅ File paths defined for train, validation, and test sets.")


# ==============================================================================
# STEP 3: CREATE A DATASET CLASS (WITH IMAGE AND MASK FIXES)
# ==============================================================================
import torch
from torch.utils.data import Dataset
import numpy as np

class CustomNumpyDataset(Dataset):
    """Dataset for loading .npy files, handles grayscale images and squeezes masks."""
    def __init__(self, images_path, masks_path):
        print(f"Loading data from: {images_path}")
        self.images = np.load(images_path)
        print(f"Loading masks from: {masks_path}")
        self.masks = np.load(masks_path)

        print(f"-> Loaded images shape: {self.images.shape}")
        print(f"-> Loaded masks shape: {self.masks.shape}")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # Load raw data
        image = self.images[idx].astype(np.float32)
        mask = self.masks[idx]

        # --- ESSENTIAL STRUCTURAL TRANSFORMATIONS ---
        # These are generally required for compatibility with the model and loss function.

        # 1. Squeeze mask from (H, W, 1) to (H, W)
        if mask.ndim == 3 and mask.shape[-1] == 1:
            mask = np.squeeze(mask, axis=-1)

        # 2. Set mask data type for PyTorch loss function
        mask = mask.astype(np.int64)

        # 3. Handle image channels (e.g., convert grayscale to 3-channel for standard models)
        if image.ndim == 2: # Grayscale (H, W) -> (3, H, W)
            image = np.stack([image] * 3, axis=0)
        elif image.ndim == 3 and image.shape[-1] == 1: # Grayscale (H, W, 1) -> (3, H, W)
            image = image.transpose(2, 0, 1)
            image = np.concatenate([image] * 3, axis=0)
        elif image.ndim == 3 and image.shape[-1] == 3: # RGB (H, W, 3) -> (3, H, W)
            image = image.transpose(2, 0, 1)

        # --- VALUE TRANSFORMATION (REMOVED) ---
        # The normalization step has been removed.
        # if image.max() > 1.0:
        #     image = image / 255.0

        # Convert to PyTorch tensors
        image_tensor = torch.from_numpy(image.copy())
        mask_tensor = torch.from_numpy(mask.copy())

        return image_tensor, mask_tensor


# ==============================================================================
# STEP 4: SETUP FCN MODEL (Cloning and Path)
# ==============================================================================
print("\n--- Setting up FCN model ---")
repo_parent_path = '/content/FCN-pytorch'
if not os.path.exists(repo_parent_path):
    !git clone -q https://github.com/pochih/FCN-pytorch.git
repo_code_path = '/content/FCN-pytorch/python'
if repo_code_path not in sys.path:
    sys.path.append(repo_code_path)
try:
    from fcn import FCN8s, VGGNet
    print("✅ Successfully imported FCN8s and VGG_net.")
except ImportError as e:
    print(f"❌ FATAL: Could not import the model. Error: {e}")

# ==============================================================================
# STEP 5: CONFIGURATION
# ==============================================================================
temp_mask = np.load(y_train_path)
NUM_CLASSES = int(np.max(temp_mask)) + 1
del temp_mask

BATCH_SIZE = 8
NUM_EPOCHS = 10
LEARNING_RATE = 1e-4
device = "cuda" if torch.cuda.is_available() else "cpu"

print("\n--- Configuration ---")
print(f"Device: {device}")
print(f"Number of Classes: {NUM_CLASSES} (determined from data)")
print(f"Batch Size: {BATCH_SIZE}")
print(f"Epochs: {NUM_EPOCHS}")

# ==============================================================================
# STEP 6: CREATE DATASETS AND DATALOADERS
# ==============================================================================
print("\n--- Creating datasets and dataloaders from your .npy files ---")
train_dataset = CustomNumpyDataset(images_path=X_train_path, masks_path=y_train_path)
val_dataset = CustomNumpyDataset(images_path=X_val_path, masks_path=y_val_path)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
print("✅ Dataloaders are ready.")


# ==============================================================================
# ### NEW ### STEP 6.5: CREATE TEST DATASET AND DATALOADER
# ==============================================================================
print("\n--- Creating test dataset and dataloader ---")
# This uses the test file paths defined in STEP 2
try:
    test_dataset = CustomNumpyDataset(images_path=X_test_path, masks_path=y_test_path)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
    print("✅ Test dataloader is ready for external validation.")
except FileNotFoundError:
    print(f"❌ WARNING: Test files not found at {X_test_path} or {y_test_path}. Skipping test loader creation.")
    test_loader = None

# ==============================================================================
# ### MODIFIED ### STEP 7: INITIALIZE MODEL, LOSS, OPTIMIZER, AND SAVE PATH
# ==============================================================================
print("\n--- Initializing Model ---")
vgg_net = VGGNet(requires_grad=True)
model = FCN8s(pretrained_net=vgg_net, n_class=NUM_CLASSES)
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# Define model save path and ensure the directory exists
MODEL_SAVE_DIR = '/content/drive/MyDrive/internship models/FCN'
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'best_fcn_model.pth')

print("✅ Model, Loss, and Optimizer are ready.")
print(f"✅ Best model will be saved to: {MODEL_SAVE_PATH}")

# ==============================================================================
# STEP 8: DEFINE METRICS FUNCTION (DICE SCORE)
# ==============================================================================
def dice_score(pred, target, num_classes, smooth=1e-6):
    pred = pred.contiguous()
    target = target.contiguous()
    dice_per_class = []
    for cls in range(num_classes):
        pred_cls = (pred == cls).float()
        target_cls = (target == cls).float()
        intersection = (pred_cls * target_cls).sum()
        union = pred_cls.sum() + target_cls.sum()
        dice = (2. * intersection + smooth) / (union + smooth)
        dice_per_class.append(dice)
    return torch.mean(torch.tensor(dice_per_class))

# ==============================================================================
# ### MODIFIED ### STEP 9: THE TRAINING & VALIDATION LOOP WITH MODEL SAVING
# ==============================================================================
print("\n--- Starting Training & Validation ---")
start_time = time.time()
history = {'train_loss': [], 'val_loss': [], 'val_dsc': []}
best_val_dsc = 0.0  # Initialize best validation DSC to track the best model

for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device, dtype=torch.long)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_loss = running_loss / len(train_loader)
    history['train_loss'].append(train_loss)

    model.eval()
    val_running_loss = 0.0
    val_running_dsc = 0.0
    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device, dtype=torch.long)
            outputs = model(images)
            loss = criterion(outputs, masks)
            val_running_loss += loss.item()
            predicted_masks = torch.argmax(outputs, dim=1)
            dsc = dice_score(predicted_masks, masks, num_classes=NUM_CLASSES)
            val_running_dsc += dsc.item()
    val_loss = val_running_loss / len(val_loader)
    val_dsc = val_running_dsc / len(val_loader)
    history['val_loss'].append(val_loss)
    history['val_dsc'].append(val_dsc)

    print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] | "
          f"Train Loss: {train_loss:.4f} | "
          f"Val Loss: {val_loss:.4f} | "
          f"Val DSC: {val_dsc:.4f}")

    # --- Check for best model and save ---
    if val_dsc > best_val_dsc:
        best_val_dsc = val_dsc
        torch.save(model.state_dict(), MODEL_SAVE_PATH)
        print(f"  -> 🎉 New best model saved! Validation DSC: {best_val_dsc:.4f}")

end_time = time.time()
print(f"\n--- Training Finished ---")
print(f"Total training time: {end_time - start_time:.2f} seconds")

# ==============================================================================
# STEP 10: PLOT TRAINING HISTORY
# ==============================================================================
print("\n--- Plotting Training History ---")
epochs_range = range(1, NUM_EPOCHS + 1)
plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, history['train_loss'], 'o-', label='Train Loss')
plt.plot(epochs_range, history['val_loss'], 'o-', label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.xticks(epochs_range)
plt.legend()
plt.grid(True)
plt.subplot(1, 2, 2)
plt.plot(epochs_range, history['val_dsc'], 'o-', label='Validation DSC', color='orange')
plt.title('Validation DSC Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Dice Score')
plt.xticks(epochs_range)
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ==============================================================================
# STEP 11: VISUALIZE PREDICTION vs. GROUND TRUTH (from last epoch)
# ==============================================================================
print("\n--- Visualizing a sample prediction from the *last* epoch model ---")
model.eval()
with torch.no_grad():
    sample_images, sample_masks = next(iter(val_loader))
    sample_images = sample_images.to(device)
    outputs = model(sample_images)
    predicted_masks = torch.argmax(outputs, dim=1)
image_to_show = sample_images[0].cpu().permute(1, 2, 0).numpy()
ground_truth_to_show = sample_masks[0].cpu().numpy()
prediction_to_show = predicted_masks[0].cpu().numpy()
if image_to_show.shape[2] == 3:
    image_to_show = image_to_show[:, :, 0]
plt.figure(figsize=(18, 6))
plt.subplot(1, 3, 1)
plt.imshow(image_to_show, cmap='gray')
plt.title("Input Image")
plt.axis('off')
plt.subplot(1, 3, 2)
plt.imshow(ground_truth_to_show, cmap='jet', vmin=0, vmax=NUM_CLASSES-1)
plt.title("Ground Truth Mask")
plt.axis('off')
plt.subplot(1, 3, 3)
plt.imshow(prediction_to_show, cmap='jet', vmin=0, vmax=NUM_CLASSES-1)
plt.title("Predicted Mask (Last Epoch)")
plt.axis('off')
plt.tight_layout()
plt.show()

# ==============================================================================
# ### NEW ### STEP 11.5: LOAD BEST MODEL FOR FINAL PREDICTIONS
# ==============================================================================
print("\n--- Loading best performing model for final predictions ---")
# Re-initialize the model structure
vgg_net_final = VGGNet(requires_grad=False) # No need for gradients now
best_model = FCN8s(pretrained_net=vgg_net_final, n_class=NUM_CLASSES)
# Load the saved state dictionary
best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))
best_model.to(device)
best_model.eval() # Set to evaluation mode
print(f"✅ Best model loaded from {MODEL_SAVE_PATH}")

# ==============================================================================
# STEP 12: GENERATE AND SAVE ALL PREDICTIONS AS JPG (USING BEST MODEL)
# ==============================================================================

# ==============================================================================
# STEP 12: GENERATE AND SAVE ALL PREDICTIONS AS JPG (USING BEST MODEL)
# ==============================================================================

print("\n--- Preparing to save all model predictions as comparison JPG images ---")

# Define output directories
internal_val_dir = '/content/drive/MyDrive/internship models/FCN/internal validation (on train set)'
external_val_dir = '/content/drive/MyDrive/internship models/FCN/external validation (on test set)'

# Create directories if they don't exist
os.makedirs(internal_val_dir, exist_ok=True)
os.makedirs(external_val_dir, exist_ok=True)
print(f"✅ Output directories are ready.")
print(f" -> Internal validation: {internal_val_dir}")
print(f" -> External validation: {external_val_dir}")

# --- 12.1: Define Post-Processing Function ---
from scipy import ndimage
def post_process_mask(mask):
    """
    Applies post-processing to a binary segmentation mask.
    Keeps the largest connected component and fills holes.
    """
    labels, num_features = ndimage.label(mask)
    if num_features == 0:
        return mask
    component_sizes = np.bincount(labels.ravel())
    if len(component_sizes) > 1:
        largest_component_label = component_sizes[1:].argmax() + 1
        processed_mask = (labels == largest_component_label)
        processed_mask = ndimage.binary_fill_holes(processed_mask)
        return processed_mask.astype(np.uint8)
    return mask

# --- 12.2: Save Predictions Function ---
def save_predictions_as_jpg(model, loader, device, output_dir, num_classes):
    """
    Generates predictions for a full dataset and saves a composite image
    (Input, Ground Truth, Raw Prediction, Post-Processed Prediction) for each sample.
    Computes and returns average Dice scores before and after post-processing.
    """
    model.eval()
    image_counter = 0
    total_images = len(loader.dataset)
    print(f"Running inference on {total_images} images, saving to: {output_dir}")

    total_dice_before = 0.0
    total_dice_after = 0.0

    with torch.no_grad():
        for images, ground_truth_masks in loader:
            images, ground_truth_masks = images.to(device), ground_truth_masks.to(device)
            outputs = model(images)
            predicted_masks_raw = torch.argmax(outputs, dim=1)

            # Apply post-processing to each predicted mask in the batch
            predicted_masks_post = torch.zeros_like(predicted_masks_raw)
            for i in range(predicted_masks_raw.shape[0]):
                predicted_masks_post[i] = torch.from_numpy(post_process_mask(predicted_masks_raw[i].cpu().numpy()))

            images_cpu = images.cpu()
            ground_truth_masks_cpu = ground_truth_masks.cpu().numpy()
            predicted_masks_raw_cpu = predicted_masks_raw.cpu().numpy()
            predicted_masks_post_cpu = predicted_masks_post.cpu().numpy()

            for i in range(images_cpu.shape[0]):
                input_image = images_cpu[i].permute(1, 2, 0).numpy()
                if input_image.shape[2] == 3:
                    input_image = input_image[:, :, 0]  # Use first channel for grayscale
                gt_mask = ground_truth_masks_cpu[i]
                pred_raw = predicted_masks_raw_cpu[i]
                pred_post = predicted_masks_post_cpu[i]

                # Calculate Dice score for this image
                pred_raw_tensor = torch.from_numpy(pred_raw).to(device)
                pred_post_tensor = torch.from_numpy(pred_post).to(device)
                gt_tensor = ground_truth_masks[i].to(device)
                dice_before = dice_score(pred_raw_tensor, gt_tensor, num_classes=num_classes).item()
                dice_after = dice_score(pred_post_tensor, gt_tensor, num_classes=num_classes).item()
                total_dice_before += dice_before
                total_dice_after += dice_after

                fig, ax = plt.subplots(1, 4, figsize=(24, 6))
                ax[0].imshow(input_image, cmap='gray'); ax[0].set_title("Input Image"); ax[0].axis('off')
                ax[1].imshow(gt_mask, cmap='jet', vmin=0, vmax=num_classes - 1); ax[1].set_title("Ground Truth Mask"); ax[1].axis('off')
                ax[2].imshow(pred_raw, cmap='jet', vmin=0, vmax=num_classes - 1); ax[2].set_title("Raw Prediction"); ax[2].axis('off')
                ax[3].imshow(pred_post, cmap='jet', vmin=0, vmax=num_classes - 1); ax[3].set_title("Post-Processed Prediction"); ax[3].axis('off')

                plt.tight_layout()
                filename = f"comparison_{image_counter:05d}.jpg"
                filepath = os.path.join(output_dir, filename)
                fig.savefig(filepath, format='jpg', bbox_inches='tight', pad_inches=0.1)
                plt.close(fig)

                image_counter += 1
                if image_counter % 50 == 0 or image_counter == total_images:
                    print(f" -> Saved {image_counter}/{total_images} comparison images...")

    avg_dice_before = total_dice_before / image_counter
    avg_dice_after = total_dice_after / image_counter
    return avg_dice_before, avg_dice_after

# --- Save Training Set Predictions (Internal Validation) ---
print("\n--- Generating comparison images for the ENTIRE training set... ---")
train_loader_no_shuffle = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
dice_before_train, dice_after_train = save_predictions_as_jpg(best_model, train_loader_no_shuffle, device, internal_val_dir, NUM_CLASSES)
print(f"\n--- Train Set Evaluation Complete ---")
print(f"Total Train Images Processed: {len(train_dataset)}")
print(f"Average Dice (Before Post-Processing): {dice_before_train:.4f}")
print(f"Average Dice (After Post-Processing):  {dice_after_train:.4f}")

# --- Save Test Set Predictions (External Validation) ---
print("\n--- Generating comparison images for the ENTIRE test set... ---")
if test_loader:
    dice_before_test, dice_after_test = save_predictions_as_jpg(best_model, test_loader, device, external_val_dir, NUM_CLASSES)
    print(f"\n--- Test Set Evaluation Complete ---")
    print(f"Total Test Images Processed: {len(test_dataset)}")
    print(f"Average Dice (Before Post-Processing): {dice_before_test:.4f}")
    print(f"Average Dice (After Post-Processing):  {dice_after_test:.4f}")
else:
    print("SKIPPED: Test loader was not created. Cannot perform external validation.")


print("\n--- All comparison images have been generated and saved successfully! ---")

"""# vastus medialis muscle

"""

# ==============================================================================
# STEP 0: SETUP AND IMPORTS
# ==============================================================================
import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import time
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive

# ==============================================================================
# STEP 1: MOUNT GOOGLE DRIVE
# ==============================================================================
print("--- Mounting Google Drive ---")
try:
    drive.mount('/content/drive', force_remount=True)
    print("✅ Google Drive mounted successfully.")
except Exception as e:
    print(f"❌ Error mounting drive: {e}")

# ==============================================================================
# STEP 2: DEFINE YOUR DATASET FILE PATHS
# ==============================================================================
print("\n--- Defining dataset file paths ---")
base_path = '/content/drive/MyDrive/intern RF longitudinal latest file/'

# Training and Validation sets (used for training and model selection)
X_train_path = os.path.join(base_path, 'X_train.npy')
y_train_path = os.path.join(base_path, 'y_train.npy')
X_val_path = os.path.join(base_path, 'X_val.npy')
y_val_path = os.path.join(base_path, 'y_val.npy')

# Test set (used for final external validation)
X_test_path = os.path.join(base_path, 'X_test.npy')
y_test_path = os.path.join(base_path, 'y_test.npy')

print("✅ File paths defined for train, validation, and test sets.")


# ==============================================================================
# STEP 3: CREATE A DATASET CLASS (WITH IMAGE AND MASK FIXES)
# ==============================================================================
import torch
from torch.utils.data import Dataset
import numpy as np

class CustomNumpyDataset(Dataset):
    """Dataset for loading .npy files, handles grayscale images and squeezes masks."""
    def __init__(self, images_path, masks_path):
        print(f"Loading data from: {images_path}")
        self.images = np.load(images_path)
        print(f"Loading masks from: {masks_path}")
        self.masks = np.load(masks_path)

        print(f"-> Loaded images shape: {self.images.shape}")
        print(f"-> Loaded masks shape: {self.masks.shape}")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # Load raw data
        image = self.images[idx].astype(np.float32)
        mask = self.masks[idx]

        # --- ESSENTIAL STRUCTURAL TRANSFORMATIONS ---
        # These are generally required for compatibility with the model and loss function.

        # 1. Squeeze mask from (H, W, 1) to (H, W)
        if mask.ndim == 3 and mask.shape[-1] == 1:
            mask = np.squeeze(mask, axis=-1)

        # 2. Set mask data type for PyTorch loss function
        mask = mask.astype(np.int64)

        # 3. Handle image channels (e.g., convert grayscale to 3-channel for standard models)
        if image.ndim == 2: # Grayscale (H, W) -> (3, H, W)
            image = np.stack([image] * 3, axis=0)
        elif image.ndim == 3 and image.shape[-1] == 1: # Grayscale (H, W, 1) -> (3, H, W)
            image = image.transpose(2, 0, 1)
            image = np.concatenate([image] * 3, axis=0)
        elif image.ndim == 3 and image.shape[-1] == 3: # RGB (H, W, 3) -> (3, H, W)
            image = image.transpose(2, 0, 1)

        # --- VALUE TRANSFORMATION (REMOVED) ---
        # The normalization step has been removed.
        # if image.max() > 1.0:
        #     image = image / 255.0

        # Convert to PyTorch tensors
        image_tensor = torch.from_numpy(image.copy())
        mask_tensor = torch.from_numpy(mask.copy())

        return image_tensor, mask_tensor


# ==============================================================================
# STEP 4: SETUP FCN MODEL (Cloning and Path)
# ==============================================================================
print("\n--- Setting up FCN model ---")
repo_parent_path = '/content/FCN-pytorch'
if not os.path.exists(repo_parent_path):
    !git clone -q https://github.com/pochih/FCN-pytorch.git
repo_code_path = '/content/FCN-pytorch/python'
if repo_code_path not in sys.path:
    sys.path.append(repo_code_path)
try:
    from fcn import FCN8s, VGGNet
    print("✅ Successfully imported FCN8s and VGG_net.")
except ImportError as e:
    print(f"❌ FATAL: Could not import the model. Error: {e}")

# ==============================================================================
# STEP 5: CONFIGURATION
# ==============================================================================
temp_mask = np.load(y_train_path)
NUM_CLASSES = int(np.max(temp_mask)) + 1
del temp_mask

BATCH_SIZE = 8
NUM_EPOCHS = 10
LEARNING_RATE = 1e-4
device = "cuda" if torch.cuda.is_available() else "cpu"

print("\n--- Configuration ---")
print(f"Device: {device}")
print(f"Number of Classes: {NUM_CLASSES} (determined from data)")
print(f"Batch Size: {BATCH_SIZE}")
print(f"Epochs: {NUM_EPOCHS}")

# ==============================================================================
# STEP 6: CREATE DATASETS AND DATALOADERS
# ==============================================================================
print("\n--- Creating datasets and dataloaders from your .npy files ---")
train_dataset = CustomNumpyDataset(images_path=X_train_path, masks_path=y_train_path)
val_dataset = CustomNumpyDataset(images_path=X_val_path, masks_path=y_val_path)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
print("✅ Dataloaders are ready.")


# ==============================================================================
# STEP 6.5: CREATE TEST DATASET AND DATALOADER
# ==============================================================================
print("\n--- Creating test dataset and dataloader ---")
# This uses the test file paths defined in STEP 2
try:
    test_dataset = CustomNumpyDataset(images_path=X_test_path, masks_path=y_test_path)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
    print("✅ Test dataloader is ready for external validation.")
except FileNotFoundError:
    print(f"❌ WARNING: Test files not found at {X_test_path} or {y_test_path}. Skipping test loader creation.")
    test_loader = None

# ==============================================================================
# STEP 7: INITIALIZE MODEL, LOSS, OPTIMIZER, AND SAVE PATH
# ==============================================================================
print("\n--- Initializing Model ---")
vgg_net = VGGNet(requires_grad=True)
model = FCN8s(pretrained_net=vgg_net, n_class=NUM_CLASSES)
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# Define model save path and ensure the directory exists
MODEL_SAVE_DIR = '/content/drive/MyDrive/internship models/FCN/vastus medialis/'
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'best_fcn_model.pth')

print("✅ Model, Loss, and Optimizer are ready.")
print(f"✅ Best model will be saved to: {MODEL_SAVE_PATH}")

# ==============================================================================
# STEP 8: DEFINE METRICS FUNCTION (DICE SCORE)
# ==============================================================================
def dice_score(pred, target, num_classes, smooth=1e-6):
    pred = pred.contiguous()
    target = target.contiguous()
    dice_per_class = []
    for cls in range(num_classes):
        pred_cls = (pred == cls).float()
        target_cls = (target == cls).float()
        intersection = (pred_cls * target_cls).sum()
        union = pred_cls.sum() + target_cls.sum()
        dice = (2. * intersection + smooth) / (union + smooth)
        dice_per_class.append(dice)
    return torch.mean(torch.tensor(dice_per_class))

# ==============================================================================
# STEP 9: THE TRAINING & VALIDATION LOOP WITH MODEL SAVING
# ==============================================================================
print("\n--- Starting Training & Validation ---")
start_time = time.time()
history = {'train_loss': [], 'val_loss': [], 'val_dsc': []}
best_val_dsc = 0.0  # Initialize best validation DSC to track the best model

for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device, dtype=torch.long)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_loss = running_loss / len(train_loader)
    history['train_loss'].append(train_loss)

    model.eval()
    val_running_loss = 0.0
    val_running_dsc = 0.0
    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device, dtype=torch.long)
            outputs = model(images)
            loss = criterion(outputs, masks)
            val_running_loss += loss.item()
            predicted_masks = torch.argmax(outputs, dim=1)
            dsc = dice_score(predicted_masks, masks, num_classes=NUM_CLASSES)
            val_running_dsc += dsc.item()
    val_loss = val_running_loss / len(val_loader)
    val_dsc = val_running_dsc / len(val_loader)
    history['val_loss'].append(val_loss)
    history['val_dsc'].append(val_dsc)

    print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] | "
          f"Train Loss: {train_loss:.4f} | "
          f"Val Loss: {val_loss:.4f} | "
          f"Val DSC: {val_dsc:.4f}")

    # --- Check for best model and save ---
    if val_dsc > best_val_dsc:
        best_val_dsc = val_dsc
        torch.save(model.state_dict(), MODEL_SAVE_PATH)
        print(f"  -> 🎉 New best model saved! Validation DSC: {best_val_dsc:.4f}")

end_time = time.time()
print(f"\n--- Training Finished ---")
print(f"Total training time: {end_time - start_time:.2f} seconds")

# ==============================================================================
# STEP 10: PLOT TRAINING HISTORY
# ==============================================================================
print("\n--- Plotting Training History ---")
epochs_range = range(1, NUM_EPOCHS + 1)
plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, history['train_loss'], 'o-', label='Train Loss')
plt.plot(epochs_range, history['val_loss'], 'o-', label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.xticks(epochs_range)
plt.legend()
plt.grid(True)
plt.subplot(1, 2, 2)
plt.plot(epochs_range, history['val_dsc'], 'o-', label='Validation DSC', color='orange')
plt.title('Validation DSC Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Dice Score')
plt.xticks(epochs_range)
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ==============================================================================
# STEP 11: VISUALIZE PREDICTION vs. GROUND TRUTH (from last epoch)
# ==============================================================================
print("\n--- Visualizing a sample prediction from the *last* epoch model ---")
model.eval()
with torch.no_grad():
    sample_images, sample_masks = next(iter(val_loader))
    sample_images = sample_images.to(device)
    outputs = model(sample_images)
    predicted_masks = torch.argmax(outputs, dim=1)
image_to_show = sample_images[0].cpu().permute(1, 2, 0).numpy()
ground_truth_to_show = sample_masks[0].cpu().numpy()
prediction_to_show = predicted_masks[0].cpu().numpy()
if image_to_show.shape[2] == 3:
    image_to_show = image_to_show[:, :, 0]
plt.figure(figsize=(18, 6))
plt.subplot(1, 3, 1)
plt.imshow(image_to_show, cmap='gray')
plt.title("Input Image")
plt.axis('off')
plt.subplot(1, 3, 2)
plt.imshow(ground_truth_to_show, cmap='jet', vmin=0, vmax=NUM_CLASSES-1)
plt.title("Ground Truth Mask")
plt.axis('off')
plt.subplot(1, 3, 3)
plt.imshow(prediction_to_show, cmap='jet', vmin=0, vmax=NUM_CLASSES-1)
plt.title("Predicted Mask (Last Epoch)")
plt.axis('off')
plt.tight_layout()
plt.show()

# ==============================================================================
# STEP 11.5: LOAD BEST MODEL FOR FINAL PREDICTIONS
# ==============================================================================
print("\n--- Loading best performing model for final predictions ---")
# Re-initialize the model structure
vgg_net_final = VGGNet(requires_grad=False) # No need for gradients now
best_model = FCN8s(pretrained_net=vgg_net_final, n_class=NUM_CLASSES)
# Load the saved state dictionary
best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))
best_model.to(device)
best_model.eval() # Set to evaluation mode
print(f"✅ Best model loaded from {MODEL_SAVE_PATH}")

# ==============================================================================
# STEP 12: GENERATE AND SAVE ALL PREDICTIONS AS JPG (USING BEST MODEL)
# ==============================================================================

print("\n--- Preparing to save all model predictions as comparison JPG images ---")

# Define output directories
internal_val_dir = '/content/drive/MyDrive/internship models/FCN/vastus medialis/comparison internal'
external_val_dir = '/content/drive/MyDrive/internship models/FCN/vastus medialis/comparison external'

# Create directories if they don't exist
os.makedirs(internal_val_dir, exist_ok=True)
os.makedirs(external_val_dir, exist_ok=True)
print(f"✅ Output directories are ready.")
print(f" -> Internal validation: {internal_val_dir}")
print(f" -> External validation: {external_val_dir}")

# --- 12.1: Define Post-Processing Function ---
from scipy import ndimage
def post_process_mask(mask):
    """
    Applies post-processing to a binary segmentation mask.
    Keeps the largest connected component and fills holes.
    """
    labels, num_features = ndimage.label(mask)
    if num_features == 0:
        return mask
    component_sizes = np.bincount(labels.ravel())
    if len(component_sizes) > 1:
        largest_component_label = component_sizes[1:].argmax() + 1
        processed_mask = (labels == largest_component_label)
        processed_mask = ndimage.binary_fill_holes(processed_mask)
        return processed_mask.astype(np.uint8)
    return mask

# --- 12.2: Save Predictions Function ---
def save_predictions_as_jpg(model, loader, device, output_dir, num_classes):
    """
    Generates predictions for a full dataset and saves a composite image
    (Input, Ground Truth, Raw Prediction, Post-Processed Prediction) for each sample.
    Computes and returns average Dice scores before and after post-processing.
    """
    model.eval()
    image_counter = 0
    total_images = len(loader.dataset)
    print(f"Running inference on {total_images} images, saving to: {output_dir}")

    total_dice_before = 0.0
    total_dice_after = 0.0

    with torch.no_grad():
        for images, ground_truth_masks in loader:
            images, ground_truth_masks = images.to(device), ground_truth_masks.to(device)
            outputs = model(images)
            predicted_masks_raw = torch.argmax(outputs, dim=1)

            # Apply post-processing to each predicted mask in the batch
            predicted_masks_post = torch.zeros_like(predicted_masks_raw)
            for i in range(predicted_masks_raw.shape[0]):
                predicted_masks_post[i] = torch.from_numpy(post_process_mask(predicted_masks_raw[i].cpu().numpy()))

            images_cpu = images.cpu()
            ground_truth_masks_cpu = ground_truth_masks.cpu().numpy()
            predicted_masks_raw_cpu = predicted_masks_raw.cpu().numpy()
            predicted_masks_post_cpu = predicted_masks_post.cpu().numpy()

            for i in range(images_cpu.shape[0]):
                input_image = images_cpu[i].permute(1, 2, 0).numpy()
                if input_image.shape[2] == 3:
                    input_image = input_image[:, :, 0]  # Use first channel for grayscale
                gt_mask = ground_truth_masks_cpu[i]
                pred_raw = predicted_masks_raw_cpu[i]
                pred_post = predicted_masks_post_cpu[i]

                # Calculate Dice score for this image
                pred_raw_tensor = torch.from_numpy(pred_raw).to(device)
                pred_post_tensor = torch.from_numpy(pred_post).to(device)
                gt_tensor = ground_truth_masks[i].to(device)
                dice_before = dice_score(pred_raw_tensor, gt_tensor, num_classes=num_classes).item()
                dice_after = dice_score(pred_post_tensor, gt_tensor, num_classes=num_classes).item()
                total_dice_before += dice_before
                total_dice_after += dice_after

                fig, ax = plt.subplots(1, 4, figsize=(24, 6))
                ax[0].imshow(input_image, cmap='gray'); ax[0].set_title("Input Image"); ax[0].axis('off')
                ax[1].imshow(gt_mask, cmap='jet', vmin=0, vmax=num_classes - 1); ax[1].set_title("Ground Truth Mask"); ax[1].axis('off')
                ax[2].imshow(pred_raw, cmap='jet', vmin=0, vmax=num_classes - 1); ax[2].set_title("Raw Prediction"); ax[2].axis('off')
                ax[3].imshow(pred_post, cmap='jet', vmin=0, vmax=num_classes - 1); ax[3].set_title("Post-Processed Prediction"); ax[3].axis('off')

                plt.tight_layout()
                filename = f"comparison_{image_counter:05d}.jpg"
                filepath = os.path.join(output_dir, filename)
                fig.savefig(filepath, format='jpg', bbox_inches='tight', pad_inches=0.1)
                plt.close(fig)

                image_counter += 1
                if image_counter % 50 == 0 or image_counter == total_images:
                    print(f" -> Saved {image_counter}/{total_images} comparison images...")

    avg_dice_before = total_dice_before / image_counter
    avg_dice_after = total_dice_after / image_counter
    return avg_dice_before, avg_dice_after

# --- Save Training Set Predictions (Internal Validation) ---
print("\n--- Generating comparison images for the ENTIRE training set... ---")
train_loader_no_shuffle = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
dice_before_train, dice_after_train = save_predictions_as_jpg(best_model, train_loader_no_shuffle, device, internal_val_dir, NUM_CLASSES)
print(f"\n--- Train Set Evaluation Complete ---")
print(f"Total Train Images Processed: {len(train_dataset)}")
print(f"Average Dice (Before Post-Processing): {dice_before_train:.4f}")
print(f"Average Dice (After Post-Processing):  {dice_after_train:.4f}")

# --- Save Test Set Predictions (External Validation) ---
print("\n--- Generating comparison images for the ENTIRE test set... ---")
if test_loader:
    dice_before_test, dice_after_test = save_predictions_as_jpg(best_model, test_loader, device, external_val_dir, NUM_CLASSES)
    print(f"\n--- Test Set Evaluation Complete ---")
    print(f"Total Test Images Processed: {len(test_dataset)}")
    print(f"Average Dice (Before Post-Processing): {dice_before_test:.4f}")
    print(f"Average Dice (After Post-Processing):  {dice_after_test:.4f}")
else:
    print("SKIPPED: Test loader was not created. Cannot perform external validation.")


print("\n--- All comparison images have been generated and saved successfully! ---")